### 웹 크롤링
	- 웹 크롤러(Web Crawler)는 웹문서, 이미지 등을 주기적으로 수집하여 자동으로 데이터베이스화하는 프로그램
	- 크롤러가 하는 작업을 웹 크롤링(Web Carwling)이라 함
	- requests와 beautifulsoup4 패키지 사용
##### 1. 문서 전체 가져오기
- urllib.request 패키지

    ```python
    from urllib.request import urlopen
    from bs4 import BeautifulSoup as bs

    html = urlopen("https://www.naver.com/")
    soup = bs(html, "html.parser")
    #print(soup)
    ```

- requests 패키지

  ```python
  import requests
  from bs4 import BeautifulSoup as bs
  
  html = requests.get("https://www.naver.com/")
  soup = bs(html.text, "html.parser")
  #print(soup)
  ```


##### 2. html 태그에서 원하는 정보 추출하기
- html 태그를 이용하는 방법

  ```python
  # class를 이용한 태그 검색
  find_div = soup.find("div", class_="group_nav")
  find_div
  
  # id를 이용한 태그 검색
  find_div = soup.find('div', id="NM_FAVORITE")
  find_div
  
  # find_all 사용
  find_div = soup.find("div", class_="group_nav")
  find_lst = find_div.find_all("li")
  for item in find_lst:
      print(item.get_text())   # 모든 태그를 제거하고 텍스트만 남김
      #print(item.text)         # 태그 내에 있는 텍스트를 추출
      print(item.find("a")["href"])  # 태그의 속성을 출력
  ```

  

- CSS Selector를 이용하는 방법

  ```python
  css_soup=soup.select("#NM_FAVORITE > div.group_nav > ul.list_nav.type_fix")  # 리스트 형식으로 출력
  css_a = css_soup[0].find_all("a")
  for a in css_a:
      print(a.text)
  ```

  
